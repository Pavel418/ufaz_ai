{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import mpl_toolkits\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file_name, isTrain):\n",
    "    train = pd.read_csv(file_name)\n",
    "    if isTrain:\n",
    "        # link in present only in train dataset\n",
    "        train = train.drop(['link'], axis=1)\n",
    "    fields = ['publication_date', 'latitude', 'longitude', 'description','category', 'floor', 'area', 'kupcha', 'rooms', 'repairs', 'hypothec', 'location attributes']\n",
    "    if isTrain:\n",
    "        fields.append('price')\n",
    "    train = train[fields]\n",
    "\n",
    "    # clean data to make it readable for the algorithm\n",
    "    train.replace('var', True, inplace=True)\n",
    "    train.replace('yoxdur', False, inplace=True)\n",
    "    train.replace(np.nan, False, inplace=True)\n",
    "    train.replace({'m²': ''}, regex=True, inplace=True)\n",
    "    train.replace('Yeni tikili', True, inplace=True)\n",
    "    train.replace('Köhnə tikili', False, inplace=True)\n",
    "    train = train.astype({\"area\": float})\n",
    "    currentFloors = []\n",
    "    maxFloors = []\n",
    "    for floor in train['floor'].array:\n",
    "        floors = floor.split(' / ')\n",
    "        currentFloors.append(floors[0])\n",
    "        maxFloors.append(floors[1])\n",
    "    train[\"current_floor\"] = currentFloors\n",
    "    train[\"max_floor\"] = maxFloors\n",
    "    \n",
    "    train = train.astype({\"current_floor\": int})\n",
    "    train = train.astype({\"max_floor\": int})\n",
    "    del train['floor']\n",
    "    \n",
    "    day = []\n",
    "    month = []\n",
    "    for index in range(0, len(train['publication_date'].array)):\n",
    "        element = train['publication_date'].array[index]\n",
    "        values = element.split(' ')\n",
    "        if values[1] == 'Yanvar':\n",
    "            month.append(1)\n",
    "        elif values[1] == 'Dekabr':\n",
    "            month.append(0)\n",
    "        day.append(values[0]) \n",
    "    del train['publication_date']\n",
    "    train['day'] = day\n",
    "    train['month'] = month\n",
    "\n",
    "    return train\n",
    "train = process('modified_train_binaaz.csv', True)\n",
    "tags = train[\"location attributes\"]\n",
    "clean_tags = tags.str.strip('[]\\'').str.split('\\', \\'')\n",
    "a = clean_tags.apply(pd.Series)\n",
    "b = a.stack()\n",
    "c = pd.get_dummies(b)\n",
    "d = c.groupby(level=0).sum()\n",
    "\n",
    "train = train.join(d)\n",
    "train = train.drop(['location attributes'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process('test_binaaz_updated.csv', False)\n",
    "tags = test[\"location attributes\"]\n",
    "test_clean_tags = tags.str.strip('[]\\'').str.split('\\', \\'')\n",
    "a = test_clean_tags.apply(pd.Series)\n",
    "b = a.stack()\n",
    "c = pd.get_dummies(b)\n",
    "d = c.groupby(level=0).sum()\n",
    "\n",
    "tags = set()\n",
    "for ls in clean_tags:\n",
    "   for tag in ls:\n",
    "    tags.add(tag)\n",
    "\n",
    "test_tags = set()\n",
    "for ls in test_clean_tags:\n",
    "   for tag in ls:\n",
    "    test_tags.add(tag)\n",
    "\n",
    "to_add = tags.difference(test_tags)\n",
    "empty = []\n",
    "for i in range(0, len(d.index)):\n",
    "    empty.append(0)\n",
    "\n",
    "map = {'price': empty}\n",
    "for add in to_add:\n",
    "    map[add] = empty\n",
    "\n",
    "additional = pd.DataFrame(map)\n",
    "\n",
    "test = test.join(d)\n",
    "test = test.join(additional)\n",
    "to_drop = ['location attributes'] + list(test_tags.difference(tags))\n",
    "test = test.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 8 candidates, totalling 160 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1300</td>\n",
       "      <td>6.968922e+09</td>\n",
       "      <td>4.525043e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500</td>\n",
       "      <td>7.226502e+09</td>\n",
       "      <td>5.185937e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900</td>\n",
       "      <td>7.380665e+09</td>\n",
       "      <td>4.800860e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1100</td>\n",
       "      <td>7.499963e+09</td>\n",
       "      <td>5.162184e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>7.596849e+09</td>\n",
       "      <td>4.466063e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>7.964661e+09</td>\n",
       "      <td>4.750369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>8.412495e+09</td>\n",
       "      <td>4.609775e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.016456e+10</td>\n",
       "      <td>5.189349e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators  mean_test_error  std_test_error\n",
       "6               1300     6.968922e+09    4.525043e+09\n",
       "7               1500     7.226502e+09    5.185937e+09\n",
       "4                900     7.380665e+09    4.800860e+09\n",
       "5               1100     7.499963e+09    5.162184e+09\n",
       "3                700     7.596849e+09    4.466063e+09\n",
       "2                500     7.964661e+09    4.750369e+09\n",
       "1                300     8.412495e+09    4.609775e+09\n",
       "0                100     1.016456e+10    5.189349e+09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'price'\n",
    "columns = train.columns.tolist()\n",
    "columns = [c for c in columns if c not in [\"price\"]]\n",
    "\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': range(100, 1501, 200),\n",
    "    # 2. 'max_depth': range(5, 71, 5),\n",
    "    # 2. 'min_samples_split': range(100, 1101, 200),\n",
    "    # 3. 'max_features': range(7, 20, 2),\n",
    "    # 4. 'subsample': [0.6,0.7,0.75,0.8,0.85,0.9]\n",
    "}\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate = 0.1, min_samples_split=500,\n",
    "                                 max_features='sqrt', subsample=0.8)\n",
    "search_cv = GridSearchCV(estimator=gbr, \n",
    "                   param_grid=param_distributions,\n",
    "                   scoring = 'neg_mean_squared_error', \n",
    "                   verbose=3,\n",
    "                   error_score='raise',\n",
    "                   n_jobs=-1,\n",
    "                   cv=20)\n",
    "\n",
    "search_cv.fit(train[columns], train[target])\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"mean_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['param_n_estimators', 'mean_test_error', 'std_test_error'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m training \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m test \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mloc[\u001b[39m~\u001b[39mtrain\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39misin(training\u001b[39m.\u001b[39mindex)]\n\u001b[1;32m----> 4\u001b[0m clf\u001b[39m.\u001b[39mfit(training[columns], training[target])\n\u001b[0;32m      5\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(test[columns])\n\u001b[0;32m      6\u001b[0m \u001b[39m# Compute error between our test predictions and the actual values.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pavel\\Documents\\GitHub\\ufaz_ai\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Pavel\\Documents\\GitHub\\ufaz_ai\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pavel\\Documents\\GitHub\\ufaz_ai\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6173\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6171\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6172\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['param_n_estimators', 'mean_test_error', 'std_test_error'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "clf = GradientBoostingRegressor(learning_rate=0.1, n_estimators = 1300, max_leaf_nodes= 50, min_samples_split=25, subsample=0.8, max_features=17, max_depth=50)\n",
    "training = train.sample(frac=0.7, random_state=5)\n",
    "test = train.loc[~train.index.isin(training.index)]\n",
    "clf.fit(training[columns], training[target])\n",
    "clf = clf.predict(test[columns])\n",
    "# Compute error between our test predictions and the actual values.\n",
    "lin_mse = mean_squared_error(clf, test[target], squared=False)\n",
    "print(\"Computed error:\", lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the result\n",
    "result = pd.DataFrame(clf)\n",
    "result.to_csv(\"result.csv\", header=['price'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e71d7ed0fa0b4c5d8ce44b530b41ec61e7cc3af5332ca9786b8048d514a256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
